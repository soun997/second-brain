---
{}
---

# 하드웨어와 제어구조


## 캐시 메모리 시스템 vs 가상 메모리 시스템

### 캐시 메모리 시스템

주기억장치에 대한 **CPU의 접근 속도를 빠르게** 하는 것이 목적

### 가상 메모리 시스템

적은 주기억장치 용량으로도 **많은 주기억장치가 있는 것처럼 사용**하는 것이 목적


## 가상 메모리의 특성

### 논리주소와 물리주소

프로세스의 메모리 주소는 논리주소로 변환하여 적재된다.
- 이는 MMU에 의해 CPU 수행 시에 물리주소로 변환된다.

### 불연속 메모리 관리

프로세스의 주소공간이 **여러 블록(페이지나 세그먼트)으로 분할**되어 **순서와 무관하게 주기억장치 상에 배치**되어 수행될 수 있다.

프로세스를 구성하는 블록 중 일부만 주기억장치 상에 적재한 채 수행할 수 있다.
- 이는 가상 메모리 관리에서만 가능하다.

#### 적재집합
- 특정 프로세스의 주소공간 중 주기억장치에 적재된 블록들의 집합

#### 메모리접근 오류
- 주기억장치에 적재되지 않은 블록이 참조될 경우 발생하는 하드웨어 이벤트(인터럽트)
- 메모리접근 오류가 발생했을 경우, 해당 프로세스는 **1)블록 상태**가 되며 **2)참조할 블록이 디스크로부터 적재될 때까지 대기**한 후 적재가 되었다면 다시 **3)준비 상태**가 된다.


## 가상메모리와 물리메모리

한 프로세스의 **전체 주소공간(가상 주소 공간)은 디스크(가상메모리)에 설정**되고, 그 중 **일부분만이 주기억장치(물리메모리)에 적재**되어 CPU에 의해 참조된다.

### 부분적재 수행의 이점

프로그램을 일부만 로드 -> 쪼개기 가능하기 때문 -> 일부만 메모리에 적재 -> 이를 관리할 필요 -> 정보 기록 필요 -> 가상 메모리를 통해 다른 주소를 쓰면서 물리 메모리를 매핑

1. 보다 많은 개수의 프로세스를 주기억장치에 유지할 수 있다.
	1. 준비 상태인 프로세스가 존재할 가능성이 높아지기 때문에 CPU 활용도가 높아진다.
2. 주기억장치보다 큰 프로세스를 수행할 수 있다.
	1. 기존 [[메모리 오버레이 기법]]의 경우, 프로그래머가 가용 메모리 크기 파악, 주소공간의 블록 분할, 언제 어떤 블록이 필요한지 파악, 주기억장치와 디스크 간의 블록 교체 작업 등을 직접 고려해야 하는 부담이 있었지만, **가상메모리의 경우에는 이를 운영체제가 담당**한다.


## 가상메모리와 물리메모리의 매핑

> 페이지(가상) 크기 = (페이지) 프레임(물리) 크기

**페이지 번호**는 가상 주소 공간을 페이지 크기로 나눈 몫으로 페이지 번호를 부여한다. (0번부터 시작)
**프레임 번호**는 주기억장치 공간을 프레임 크기로 나눈 몫으로 프레임 번호를 부여한다. (0번부터 시작)

가상주소를 물리주소로 변환하는 과정은 **MMU**(메모리 관리장치)에 의해 수행된다.
- 주소간의 변환관계를 정의한 정보는 **페이지 테이블**에 보관한다. (OS가 관리)
- 페이지 테이블에 매핑 정보가 없을 경우에는 메모리 접근 오류가 발생한 것이므로, 프로세스는 참조할 블록이 디스크로부터 적재될 때까지 대기 상태가 된다.


## 가상메모리의 동작 원리

가상메모리의 동작에는 CPU, MMU, OS가 관여한다.

1. CPU는 가상메모리 주소공간 중 특정 주소를 접근 (가상주소/논리주소)
2. MMU는 이 주소가 현재 물리메모리에 있는지 페이지 테이블을 참조해 판단
	1. **현재 물리메모리에 있는 주소라면** 
		1. 가상주소를 물리주소로 변환하여 CPU의 해당 물리메모리 접근을 허용
	2. **현재 물리메모리에 없는 주소라면**
		1. OS는 물리메모리에 빈 공간을 만들고 **디스크에서 해당 주소의 내용을 물리 메모리로 복사** 및 **페이지 테이블 갱신**
		2. 가상주소를 물리주소로 변환하여 CPU의 해당 물리메모리 접근을 허용


## 가상메모리의 실용성

### 요구 페이징 (demand paging)

프로그램 수행에 필요한 페이지만 적재하므로, 비사용 블록 적재로 인한 낭비 최소화

### 페이지 적재 요구가 얼마나 빈번한지?

임의의 구간을 관찰했을 때, 메모리 참조 행태가 너무 분산되지 않아야 한다.
- 한 번 주기억장치에 적재된 블록들이 swap-out되기 전까지 **최대한 많이 참조되도록 관리**해야 한다. (지역성의 원리)

시스템이 안정상태에 있을 경우, 주기억장치 전체가 각 프로세스의 블록들로 채워진다.
- 이 때, **주기억장치에 적재되지 않은 블록이 참조되면 이미 적재된 블록을 교체**해야 한다.

결론적으로 가상메모리의 실용성을 위해서는 **쓰레싱 방지**가 관건이다.
- 쓰레싱(thrashing): 시스템이 프로세스 수행보다 블록 교체에 대부분의 시간을 소비하게 되는 현상

### 프로세스의 성긴(sparse) 주소공간 활용

스택은 위에서 아래로, 힙은 아래에서 위로 할당된다.
- 이 때 중간의 공백도 가상 주소 공간의 일부이다.

가상 메모리에서 공백은 실제 메모리가 할당되지 않는다.
- 스택이나 힙이 확장되어야만 실제 물리 페이지를 요구하게 된다.
- **현재 직접적으로 필요하지 않은 메모리 공간은 물리 메모리에 올리지 않는다.**

### 공유 라이브러리

시스템 라이브러리를 여러 프로세스가 공유하는 것이다.
- 각 프로세스들은 공유 라이브러리를 자신의 가상 주소공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.

데이터용 공유 메모리(shared memory)

`fork()` 시 자식 프로세스의 빠른 생성이 가능하다.
- 복사하는 것이 아닌, 페이지들을 공유하기 때문이다.

### 쓰기 시 복사

초기에는 부모, 자식 프로세스가 페이지들을 공유한다.

공유된 페이지의 내용을 변경할 때만 **해당 페이지를 복사하여 새로운 페이지를 만들고**, **해당 프로세스의 페이지 테이블을 갱신**한다.

### 메모리 사상 파일

디스크의 파일을 메모리에 매핑시키고, 메모리에 접근하듯이 파일을 사용한다.
- 파일 접근과 사용을 단순화 한다. (`read()`, `write()` 없이 파일 데이터 사용, `mmap()` 시스템 호출)

![[Pasted image 20240124224733.png|500]]

## 지역성의 원리

프로세스의 메모리 참조가 군집을 이루는 특성

### 시간 지역성
- 한 번 접근된 메모리는 곧 다시 접근될 가능성이 높다.
- 반복문, 스택, 카운터 변수, 함수 호출

### 공간 지역성
- 한 번 부른 메모리의 근처를 접근할 확률이 높다.
- 순차 수행, 배열 순회

### 순차 지역성
- 여러 작업들은 순서대로 진행되는 경향이 있다.


## 페이징

**가상메모리**(디스크)는 **고정크기의 페이지로 분할**되고, **물리메모리**(주기억장치)는 **페이지 크기의 프레임(페이지 프레임)들로 분할**된다. (페이지 크기 = 프레임 크기)

### 페이지 테이블

페이지 테이블은 프로세스마다 하나씩 생성된다.

#### 가상주소
- <mark style="background: #FFB8EBA6;">가상페이지 번호</mark>
- <mark style="background: #FFF3A3A6;">가상페이지 오프셋</mark>

#### 페이지 테이블
- <mark style="background: #FFB8EBA6;">페이지 번호</mark>
- 유효비트 (0: 주기억장치에 적재 X, 1: 주기억장치에 적재 O)
- 변경비트
	- 페이지에 올라온 후 데이터 변경이 있었는지 알려주는 비트
- 접근비트
	- 페이지에 올라온 후 사용한 적이 있는지 알려주는 비트
- 주소 필드
	- 디스크 주소
	- <mark style="background: #FFB86CA6;">페이지 프레임 번호</mark>

#### 물리주소
- <mark style="background: #FFB86CA6;">페이지 프레임 번호</mark>
- <mark style="background: #FFF3A3A6;">가상페이지 오프셋</mark>

### 페이지 테이블 크기

가상주소공간의 크기가 커질 수록 페이지 테이블의 크기가 증가한다.
- 페이지의 최대 개수만큼의 PTE(Page Table Entry)가 필요하다.
- 페이지 테이블 검색 시, 이를 주기억장치에 적재하기 때문에 **주기억장치에는 보다 큰 페이지 테이블 적재 공간이 필요해지는 문제 발생**

#### n-단계 계층구조
- 페이지 테이블을 다단계로 만들고, 기본이 되는 **루트 페이지 테이블만 주기억장치에 상주시키고**, 하위 단계 페이지 테이블은 가상메모리 공간에 위치시킨다.

#### 역페이지테이블
- 개수가 적은 프레임 메모리를 중심으로 검색
- 운영체제는 모든 프로세스가 공유하는 역페이지 테이블을 별도로 생성한다.
	- 프레임 당 하나의 PTE로 역페이지 테이블을 구성하고 이를 주기억장치에 위치시킨다.
	- PTE의 개수는 물리메모리의 프레임 개수와 같다. (물리메모리를 그대로 사용)
- MMU는 역페이지 테이블 내에서 페이지 번호를 검색하고, 존재한다면 연결되어 있는 프레임 번호를 바로 참고한다.
- 하나의 프레임을 여러 프로세스가 이용할 수 있으므로 검색 시에 프로세스 ID도 확인해야 한다.
	- 해싱기법(=연결기법)을 사용하여 PTE 안에 짧은 체인을 생성한다. (충돌 예방)
- 기존의 페이지 테이블에서 PTE를 인덱싱하는 방식과 달리 순차 탐색하기 때문에 `O(n)`의 시간복잡도가 소요된다.
	- 검색속도를 위해 연관검색 또는 해시(hash)함수를 이용한다.

#### TLB(Translation Lookahead Buffer)
- 최근에 처리된 페이지 테이블의 정보를 갖는 고속 캐시
- 페이지 테이블에 접근하지 않고 고속 캐시로 빠르게 처리하는 것 (1번의 주기억장치 접근)

##### TLB에 대한 연관사상
- TLB 내에 원하는 페이지 번호가 있는지는 연관사상 방식으로 검색한다. (연관 검색)
	- 모든 페이지 번호들이 존재하는 것은 아니기 때문에, 빠른 연관메모리와 하드웨어의 도움을 받아 빠르게 검색한다.

##### 연관메모리
- 연관 기억 장치 또는 내용 지정 메모리 (CAM: Content Addressable Memory)
- 병렬 판독 회로를 내장하고 있어서 한 번에 전체의 내용의 비교 가능 (m라인을 한꺼번에 비교)
	- 캐시 메모리보다 훨씬 빠르지만 가격이 매우 비싸다.

### 페이지 크기

#### 작은 크기의 페이지
- 페이지 테이블의 크기 증가
- 페이지의 부재 비율 상승(복수 폴트)
- 장기적 관점으로는 페이지 부재 비율 감소
	- 실제로 사용되는 작은 조각들이 많이 존재
- 내부 단편화 감소
- 디스크 입출력 증가

#### 큰 크기의 페이지
- 페이지 테이블의 크기 감소
- 페이지 부재 비율 감소(복수 폴트)
- 장기적 관점으로는 페이지 부재 비율 증가
	- 큰 덩어리 몇 개만이 존재하기 때문이다.
- 내부 단편화 증가
- 디스크 입출력 감소


## 32bit 운영체제에서 최대 메모리가 4GB인 이유

2^10 = 1024 = 1KB
2^20 = 1MB
2^30 = 1GB

그러므로 2^32 = 2^30 * 2^2 = 4GB


## Ref

[가상 메모리 관리](https://velog.io/@jsb100800/CS-%EC%8A%A4%ED%84%B0%EB%94%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC)
[가상 메모리 (Virtual Memory)](https://velog.io/@xx0hn/CS-OS-%EA%B0%80%EC%83%81-%EB%A9%94%EB%AA%A8%EB%A6%AC-Virtual-Memory)
역페이지 테이블
https://itstory1592.tistory.com/103
https://neos518.tistory.com/125
https://m.blog.naver.com/kgr2626/222147145792